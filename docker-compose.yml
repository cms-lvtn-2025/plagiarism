version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: plagiarism-es
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q 'green\\|yellow'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Ollama - uncomment if you want to run Ollama in Docker
  # Note: For GPU support, you need nvidia-docker
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: plagiarism-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   # For GPU support, uncomment:
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]

  plagiarism-service:
    image: thaily/plagiarism:latest
    # build:
    #   context: .
    #   dockerfile: Dockerfile
    container_name: plagiarism-service
    ports:
      - "50051:50051"
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=9200
      - OLLAMA_HOST=http://host.docker.internal:11434
      - GRPC_HOST=0.0.0.0
      - GRPC_PORT=50051
    volumes:
      - ./certs:/app/certs:ro
    depends_on:
      elasticsearch:
        condition: service_healthy
    # For Linux, use host network to access Ollama on localhost
    # extra_hosts:
    #   - "host.docker.internal:host-gateway"

volumes:
  es_data:
    driver: local
  # ollama_data:
  #   driver: local
