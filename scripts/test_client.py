#!/usr/bin/env python3
"""Test client for Plagiarism Detection Service."""

import sys
sys.path.insert(0, ".")

import grpc
from src import plagiarism_pb2, plagiarism_pb2_grpc


def get_stub():
    """Get gRPC stub."""
    channel = grpc.insecure_channel("localhost:50051")
    return plagiarism_pb2_grpc.PlagiarismServiceStub(channel)


def test_health_check():
    """Test health check."""
    print("=" * 50)
    print("TEST: Health Check")
    print("=" * 50)

    stub = get_stub()
    response = stub.HealthCheck(plagiarism_pb2.HealthCheckRequest())

    print(f"Healthy: {response.healthy}")
    for name, health in response.components.items():
        print(f"  - {name}: {'âœ…' if health.healthy else 'âŒ'} {health.message}")

    return response.healthy


def test_upload_documents():
    """Test uploading documents."""
    print("\n" + "=" * 50)
    print("TEST: Upload Documents")
    print("=" * 50)

    stub = get_stub()

    # Sample documents
    documents = [
        {
            "title": "Luáº­n vÄƒn vá» Machine Learning",
            "content": """
            Machine Learning lÃ  má»™t nhÃ¡nh cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o, cho phÃ©p mÃ¡y tÃ­nh há»c tá»« dá»¯ liá»‡u
            mÃ  khÃ´ng cáº§n Ä‘Æ°á»£c láº­p trÃ¬nh má»™t cÃ¡ch rÃµ rÃ ng. CÃ¡c thuáº­t toÃ¡n Machine Learning xÃ¢y dá»±ng
            mÃ´ hÃ¬nh dá»±a trÃªn dá»¯ liá»‡u máº«u, Ä‘Æ°á»£c gá»i lÃ  dá»¯ liá»‡u huáº¥n luyá»‡n, Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n hoáº·c
            quyáº¿t Ä‘á»‹nh mÃ  khÃ´ng cáº§n Ä‘Æ°á»£c láº­p trÃ¬nh cá»¥ thá»ƒ Ä‘á»ƒ thá»±c hiá»‡n nhiá»‡m vá»¥ Ä‘Ã³.

            Deep Learning lÃ  má»™t phÆ°Æ¡ng phÃ¡p trong Machine Learning sá»­ dá»¥ng máº¡ng nÆ¡-ron nhÃ¢n táº¡o
            vá»›i nhiá»u lá»›p áº©n. CÃ¡c máº¡ng nÆ¡-ron sÃ¢u nÃ y cÃ³ kháº£ nÄƒng há»c cÃ¡c biá»ƒu diá»…n dá»¯ liá»‡u phá»©c táº¡p
            vÃ  Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ vÆ°á»£t trá»™i trong nhiá»u tÃ¡c vá»¥ nhÆ° nháº­n dáº¡ng hÃ¬nh áº£nh, xá»­ lÃ½ ngÃ´n ngá»¯
            tá»± nhiÃªn vÃ  chÆ¡i game.
            """,
            "metadata": {"author": "Nguyen Van A", "year": "2024", "subject": "AI"},
        },
        {
            "title": "NghiÃªn cá»©u vá» Natural Language Processing",
            "content": """
            Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP) lÃ  má»™t lÄ©nh vá»±c cá»§a khoa há»c mÃ¡y tÃ­nh vÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o
            liÃªn quan Ä‘áº¿n sá»± tÆ°Æ¡ng tÃ¡c giá»¯a mÃ¡y tÃ­nh vÃ  ngÃ´n ngá»¯ cá»§a con ngÆ°á»i. NLP giÃºp mÃ¡y tÃ­nh
            hiá»ƒu, diá»…n giáº£i vÃ  táº¡o ra ngÃ´n ngá»¯ tá»± nhiÃªn má»™t cÃ¡ch cÃ³ Ã½ nghÄ©a.

            CÃ¡c á»©ng dá»¥ng phá»• biáº¿n cá»§a NLP bao gá»“m: dá»‹ch mÃ¡y, phÃ¢n tÃ­ch cáº£m xÃºc, chatbot, tÃ³m táº¯t vÄƒn báº£n,
            vÃ  nháº­n dáº¡ng thá»±c thá»ƒ cÃ³ tÃªn. Vá»›i sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nhÆ° GPT vÃ  BERT,
            NLP Ä‘Ã£ cÃ³ nhá»¯ng bÆ°á»›c tiáº¿n vÆ°á»£t báº­c trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y.
            """,
            "metadata": {"author": "Tran Thi B", "year": "2024", "subject": "NLP"},
        },
        {
            "title": "BÃ i viáº¿t vá» Elasticsearch",
            "content": """
            Elasticsearch lÃ  má»™t cÃ´ng cá»¥ tÃ¬m kiáº¿m vÃ  phÃ¢n tÃ­ch phÃ¢n tÃ¡n, mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c xÃ¢y dá»±ng
            trÃªn Apache Lucene. Elasticsearch cho phÃ©p lÆ°u trá»¯, tÃ¬m kiáº¿m vÃ  phÃ¢n tÃ­ch khá»‘i lÆ°á»£ng lá»›n
            dá»¯ liá»‡u má»™t cÃ¡ch nhanh chÃ³ng vÃ  gáº§n nhÆ° theo thá»i gian thá»±c.

            Elasticsearch há»— trá»£ tÃ¬m kiáº¿m vector (vector search) cho phÃ©p tÃ¬m kiáº¿m dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
            ngá»¯ nghÄ©a. Äiá»u nÃ y ráº¥t há»¯u Ã­ch cho cÃ¡c á»©ng dá»¥ng nhÆ° tÃ¬m kiáº¿m ngá»¯ nghÄ©a, há»‡ thá»‘ng Ä‘á» xuáº¥t,
            vÃ  phÃ¡t hiá»‡n Ä‘áº¡o vÄƒn. Vector search sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n nhÆ° kNN Ä‘á»ƒ tÃ¬m cÃ¡c vector gáº§n nháº¥t.
            """,
            "metadata": {"author": "Le Van C", "year": "2024", "subject": "Database"},
        },
    ]

    uploaded_ids = []
    for doc in documents:
        response = stub.UploadDocument(
            plagiarism_pb2.UploadRequest(
                title=doc["title"],
                content=doc["content"],
                metadata=doc["metadata"],
                language="vi",
            )
        )

        status = "âœ…" if response.success else "âŒ"
        print(f"{status} {response.title}")
        print(f"   ID: {response.document_id}")
        print(f"   Chunks: {response.chunks_created}")
        print(f"   Message: {response.message}")

        if response.success:
            uploaded_ids.append(response.document_id)

    return uploaded_ids


def test_check_plagiarism():
    """Test plagiarism checking."""
    print("\n" + "=" * 50)
    print("TEST: Check Plagiarism")
    print("=" * 50)

    stub = get_stub()

    # Test cases
    test_cases = [
        {
            "name": "Copy nguyÃªn vÄƒn (CRITICAL)",
            "text": """
            Machine Learning lÃ  má»™t nhÃ¡nh cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o, cho phÃ©p mÃ¡y tÃ­nh há»c tá»« dá»¯ liá»‡u
            mÃ  khÃ´ng cáº§n Ä‘Æ°á»£c láº­p trÃ¬nh má»™t cÃ¡ch rÃµ rÃ ng. CÃ¡c thuáº­t toÃ¡n Machine Learning xÃ¢y dá»±ng
            mÃ´ hÃ¬nh dá»±a trÃªn dá»¯ liá»‡u máº«u, Ä‘Æ°á»£c gá»i lÃ  dá»¯ liá»‡u huáº¥n luyá»‡n.
            """,
        },
        {
            "name": "Paraphrase nháº¹ (HIGH/MEDIUM)",
            "text": """
            Há»c mÃ¡y lÃ  má»™t phÃ¢n ngÃ nh cá»§a AI, giÃºp computer cÃ³ thá»ƒ há»c há»i tá»« data
            mÃ  khÃ´ng cáº§n láº­p trÃ¬nh cá»¥ thá»ƒ. CÃ¡c algorithm ML táº¡o model tá»« training data
            Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c prediction hoáº·c decision.
            """,
        },
        {
            "name": "Ná»™i dung má»›i (SAFE)",
            "text": """
            Blockchain lÃ  má»™t cÃ´ng nghá»‡ sá»• cÃ¡i phÃ¢n tÃ¡n, cho phÃ©p lÆ°u trá»¯ dá»¯ liá»‡u má»™t cÃ¡ch
            an toÃ n vÃ  minh báº¡ch. Bitcoin lÃ  á»©ng dá»¥ng Ä‘áº§u tiÃªn vÃ  ná»•i tiáº¿ng nháº¥t cá»§a blockchain.
            Smart contract trÃªn Ethereum má»Ÿ ra nhiá»u kháº£ nÄƒng má»›i cho cÃ¡c á»©ng dá»¥ng phi táº­p trung.
            """,
        },
    ]

    for case in test_cases:
        print(f"\nğŸ“ {case['name']}")
        print("-" * 40)

        response = stub.CheckPlagiarism(
            plagiarism_pb2.CheckRequest(
                text=case["text"],
            )
        )

        severity_icons = {
            0: "ğŸŸ¢ SAFE",
            1: "ğŸŸ¡ LOW",
            2: "ğŸŸ  MEDIUM",
            3: "ğŸ”´ HIGH",
            4: "â›” CRITICAL",
        }

        print(f"Plagiarism: {response.plagiarism_percentage:.1f}%")
        print(f"Severity: {severity_icons.get(response.severity, 'UNKNOWN')}")
        print(f"Explanation: {response.explanation[:200]}...")

        if response.matches:
            print(f"Matches found: {len(response.matches)}")
            for i, match in enumerate(response.matches[:3], 1):
                print(f"  {i}. {match.document_title} ({match.similarity_score:.1%})")

        print(f"Processing time: {response.metadata.processing_time_ms}ms")


def test_search_documents():
    """Test document search."""
    print("\n" + "=" * 50)
    print("TEST: Search Documents")
    print("=" * 50)

    stub = get_stub()

    response = stub.SearchDocuments(
        plagiarism_pb2.SearchRequest(
            query="Machine Learning",
            limit=10,
        )
    )

    print(f"Found: {response.total} documents")
    for doc in response.documents:
        print(f"  - {doc.title} ({doc.chunk_count} chunks)")


def main():
    """Run all tests."""
    print("\nğŸš€ PLAGIARISM DETECTION SERVICE - TEST CLIENT\n")

    # Test 1: Health check
    if not test_health_check():
        print("âŒ Service not healthy, aborting tests")
        return

    # Test 2: Upload documents
    uploaded_ids = test_upload_documents()

    if not uploaded_ids:
        print("âŒ No documents uploaded, aborting tests")
        return

    # Test 3: Search documents
    test_search_documents()

    # Test 4: Check plagiarism
    test_check_plagiarism()

    print("\n" + "=" * 50)
    print("âœ… ALL TESTS COMPLETED")
    print("=" * 50)


if __name__ == "__main__":
    main()
